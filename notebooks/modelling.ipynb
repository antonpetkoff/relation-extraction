{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "import data_utils\n",
    "\n",
    "sys.path.insert(0, '../models')\n",
    "import log_reg_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data_utils.load_data_set('../data/train/train.csv')\n",
    "df_train_x = df_train[['head.word', 'tail.word', 'sentence']]\n",
    "df_train_y = df_train['relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = log_reg_word_embeddings.LogRegWordEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n",
      "0    [she, also, oversaw, refinancing, state, super...\n",
      "1    [more, 2, 5, million, cubic, yards, contaminat...\n",
      "2    [the, onondaga, nation, 1, 500, members, feder...\n",
      "3    [he, born, istanbul, raised, eastern, city, ad...\n",
      "4    [by, end, recent, tour, rollins, met, soldiers...\n",
      "Name: sentence, dtype: object\n",
      "Averaging word embeddings...\n",
      "0    [-0.024940285714285717, -0.014328357142857137,...\n",
      "1    [0.022366650000000002, 0.060093550000000016, -...\n",
      "2    [-0.02160072727272727, 0.10642886363636364, -0...\n",
      "3    [0.012861874999999998, 0.0178651875, -0.102017...\n",
      "4    [0.07083508108108107, 0.03429608108108108, -0....\n",
      "Name: sentence, dtype: object\n",
      "Shape of transformed input: (522517, 50)\n",
      "Fitting label encoder...\n",
      "['/broadcast/content/location' '/broadcast/producer/location'\n",
      " '/business/business_location/parent_company' '/business/company/advisors'\n",
      " '/business/company/founders' '/business/company/industry'\n",
      " '/business/company/locations' '/business/company/major_shareholders'\n",
      " '/business/company/place_founded'\n",
      " '/business/company_advisor/companies_advised'\n",
      " '/business/company_shareholder/major_shareholder_of'\n",
      " '/business/person/company' '/business/shopping_center/owner'\n",
      " '/business/shopping_center_owner/shopping_centers_owned'\n",
      " '/film/film/featured_film_locations' '/film/film_festival/location'\n",
      " '/film/film_location/featured_in_films'\n",
      " '/location/administrative_division/country' '/location/br_state/capital'\n",
      " '/location/cn_province/capital'\n",
      " '/location/country/administrative_divisions' '/location/country/capital'\n",
      " '/location/de_state/capital' '/location/fr_region/capital'\n",
      " '/location/in_state/administrative_capital'\n",
      " '/location/in_state/judicial_capital'\n",
      " '/location/in_state/legislative_capital' '/location/it_region/capital'\n",
      " '/location/jp_prefecture/capital' '/location/location/contains'\n",
      " '/location/mx_state/capital' '/location/neighborhood/neighborhood_of'\n",
      " '/location/province/capital' '/location/us_county/county_seat'\n",
      " '/location/us_state/capital' '/people/deceased_person/place_of_burial'\n",
      " '/people/deceased_person/place_of_death'\n",
      " '/people/ethnicity/geographic_distribution'\n",
      " '/people/ethnicity/included_in_group' '/people/ethnicity/includes_groups'\n",
      " '/people/ethnicity/people' '/people/family/country'\n",
      " '/people/family/members' '/people/person/children'\n",
      " '/people/person/ethnicity' '/people/person/nationality'\n",
      " '/people/person/place_lived' '/people/person/place_of_birth'\n",
      " '/people/person/profession' '/people/person/religion'\n",
      " '/people/place_of_interment/interred_here'\n",
      " '/people/profession/people_with_this_profession'\n",
      " '/sports/sports_team/location' '/sports/sports_team_location/teams'\n",
      " '/time/event/locations' 'NA']\n",
      "Transforming labels...\n",
      "Fitting model...\n"
     ]
    }
   ],
   "source": [
    "model.fit(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n",
      "0    [she, also, oversaw, refinancing, state, super...\n",
      "1    [more, 2, 5, million, cubic, yards, contaminat...\n",
      "2    [the, onondaga, nation, 1, 500, members, feder...\n",
      "3    [he, born, istanbul, raised, eastern, city, ad...\n",
      "4    [by, end, recent, tour, rollins, met, soldiers...\n",
      "Name: sentence, dtype: object\n",
      "Averaging word embeddings...\n",
      "0    [-0.024940285714285717, -0.014328357142857137,...\n",
      "1    [0.022366650000000002, 0.060093550000000016, -...\n",
      "2    [-0.02160072727272727, 0.10642886363636364, -0...\n",
      "3    [0.012861874999999998, 0.0178651875, -0.102017...\n",
      "4    [0.07083508108108107, 0.03429608108108108, -0....\n",
      "Name: sentence, dtype: object\n",
      "Shape of transformed input: (5, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NA', 'NA', 'NA', 'NA', 'NA'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df_train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_dir = '../trained_models/log_reg_word_embeddings.pkl'\n",
    "with open(save_dir, 'wb') as save_file:\n",
    "    pickle.dump(model.model, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_dir, 'rb') as saved_file:\n",
    "    loaded_model = pickle.load(saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=4, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data_utils.load_data_set('../data/test/test.csv')\n",
    "df_test_x = df_train[['head.word', 'tail.word', 'sentence']]\n",
    "df_test_y = df_train['relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n",
      "0    [she, also, oversaw, refinancing, state, super...\n",
      "1    [more, 2, 5, million, cubic, yards, contaminat...\n",
      "2    [the, onondaga, nation, 1, 500, members, feder...\n",
      "3    [he, born, istanbul, raised, eastern, city, ad...\n",
      "4    [by, end, recent, tour, rollins, met, soldiers...\n",
      "Name: sentence, dtype: object\n",
      "Averaging word embeddings...\n",
      "0    [-0.024940285714285717, -0.014328357142857137,...\n",
      "1    [0.022366650000000002, 0.060093550000000016, -...\n",
      "2    [-0.02160072727272727, 0.10642886363636364, -0...\n",
      "3    [0.012861874999999998, 0.0178651875, -0.102017...\n",
      "4    [0.07083508108108107, 0.03429608108108108, -0....\n",
      "Name: sentence, dtype: object\n",
      "Shape of transformed input: (522517, 50)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(df_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NA': 499204,\n",
       "         '/location/location/contains': 15861,\n",
       "         '/location/neighborhood/neighborhood_of': 3674,\n",
       "         '/business/person/company': 497,\n",
       "         '/people/person/nationality': 1602,\n",
       "         '/location/country/capital': 523,\n",
       "         '/location/country/administrative_divisions': 710,\n",
       "         '/people/person/place_lived': 439,\n",
       "         '/people/deceased_person/place_of_death': 1,\n",
       "         '/business/company/founders': 6})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(predictions)\n",
    "\n",
    "predicted_labels = predictions\n",
    "gold_labels = df_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7346880579961992,\n",
       " 'precision': 0.6301679116706429,\n",
       " 'recall': 0.7346880579961992,\n",
       " 'f1': 0.6516748864717016}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def compute_score(predicted_labels, gold_labels, average='weighted'):\n",
    "    accuracy = accuracy_score(gold_labels, predicted_labels)\n",
    "    precision = precision_score(gold_labels, predicted_labels, average=average)\n",
    "    recall = recall_score(gold_labels, predicted_labels, average=average)\n",
    "    f1 = f1_score(gold_labels, predicted_labels, average=average)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "compute_score(predicted_labels, gold_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
